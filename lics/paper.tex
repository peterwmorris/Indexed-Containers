\documentclass[10pt, conference, compsocconf]{IEEEtran} 
\usepackage{url}
\usepackage{times}
\usepackage{amsmath}
\usepackage{xypic}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{stmaryrd}

\usepackage{color}

%\renewcommand{\cite}[1]{\texttt{[#1]}}

\input{defs.tex}

\begin{document}
\author{\IEEEauthorblockN{Thorsten Altenkirch, Peter Morris}
\IEEEauthorblockA{University of Nottingham\\
Nottingham, UK\\
\{txa,pwm\}@cs.nott.ac.uk}}

\title{Indexed Containers}

\maketitle

\begin{abstract}
  We show that the syntactically rich notion of inductive families can
  be reduced to a core type theory with a fixed number of type
  constructors exploiting the novel notion of indexed containers.
  Indexed containers generalize simple containers, capturing strictly
  positive families instead of just strictly positive types, without
  having to extend the core type theory. Other applications of indexed
  containers include datatype-generic programming and reasoning about
  polymorphic functions. The construction presented here has been
  formalized using the Agda system.
\end{abstract}

\begin{IEEEkeywords}
Type Theory; functional programming; 

\end{IEEEkeywords}

\section{Introduction}
\label{sec:intro}

\noindent Inductive datatypes are a central feature of modern Type Theory
(e.g. COQ~\cite{CIC}) or functional programming (e.g. 
Haskell\footnote{Here we shall view Haskell as an approximation of strong
  functional programming as proposed by Turner \cite{sfp} and ignore
non-termination.})
. A simple example
is the type (or set) of de Bruijn $\lambda$-terms $\Lam\in\Set$, which can be
specified as the inductive type generated by the following
constructors
\footnote{Using a 2-dimensional syntax inspired by the
Epigram~\cite{epigram}}:
\[
\ru{i\in\Nat}
{\var\,i \in \Lam}
\qquad
\ru{t,u \in \Lam}
{\app\,t\,u\in\Lam}
\qquad
\ru{t\in\Lam}{\lam\,t\in\Lam}\]\vspace{-5ex}

\noindent
Of course, we don't
have to assume the natural numbers as primitive, but instead give an inductive
definition \`{a} la Peano:

\[
\ax{0 \in \Nat}
\qquad
\ru{n\in\Nat}{\succ\,n\in\Nat}\]\vspace{-5ex}

\noindent
An elegant way to formalize and reason about inductive types is to
model them as the initial algebra of an endofunctor, e.g. in the case of
natural numbers $F_\Nat\,X = 1+X$ and in the case of $\lambda$-terms
$F_\Lam\,X = \Nat + X\times X + X$. This perspective has been very
successful in providing a generic approach to programming with and
reasoning about inductive types, e.g. see the \emph{Algebra of
  Programming} \cite{BirdDeMoor:AlgProp}.

While the theory of inductive types is well developed, we often want
to have a finer, more expressive, notion of types, for example to
ensure the absence of run time errors --- access to arrays out of
range or access to an undefined variable in the previous example of
$\lambda$-terms. To model this we move to the notion of an inductive
family in Type Theory. We can for example define the set of $\lambda$-terms
$\Lam\,n$ with at most $n$ free variables. Indeed, we can view $\Lam$
as a function $\Nat\to\Set$ which assigns to every natural number, $n$,
the type of $\lambda$-terms with $n$ free variables. Functions whose
codomain is $\Set$ we call families. To define $\Lam$ we first
introduce the family of finite sets, $\Fin\in\Nat\to\Set$, which assigns
to $n$ a type with exactly $n$ elements:
\[
\ru{n\in\Nat}{\fzero\in\Fin\,(n+1)}
\qquad
\ru{i\in\Fin\,n}{\fsucc\,i\in\Fin\,(n+1)}\]\vspace{-5ex}

\noindent
which we use to encode the de Bruijn variables in the representation
of $\lambda$-terms ($\Lam\in\Nat\to\Set$):
\[
\ru{i\in\Fin\,n} {\var\,i \in \Lam\,n} \qquad \ru{t,u \in \Lam\,n}
{\app\,t\,u\in\Lam\,n} \qquad
\ru{t\in\Lam\,(n+1)}{\lam\,t\in\Lam\,n}\] \vspace{-5ex}

\noindent
Importantly, the constructor
$\lam$ reduces the number of \emph{free} variables by one --- by
binding one. 
Inductive families may be mutually defined, for example the $\beta$
normal forms and neutral $\lambda$-terms ($\Nf,\Ne \in \Nat\to\Set$)
\[\begin{array}{c}
\ru{i\in\Fin\,n} {\var\,i \in \Ne\,n} \qquad \ru{t\in \Ne\,n\quad u \in \Nf\,n}
{\app\,t\,u\in\Ne\,n}\\
\ru{t\in\Nf\,(n+1)}{\lam\,t\in\Nf\,n}
\qquad
\ru{t\in\Ne\,n}{\mathrm{ne}\,t\in\Nf\,n}\end{array}
\] \vspace{-5ex}

\noindent
Inductive families are the backbone of
dependently typed programming as present in Epigram or
Agda~\cite{Agda}. Coq also supports the definition of inductive families
but programming with them is rather hard --- a situation which has been
improved by the new \texttt{Program} tactic~\cite{sozeau}. 
More recently, the implementation of Generalized Algebraic Datatypes 
(GADTs)~\cite{Hinze:GADT} 
allows $\Fin$ and $\Lam$ to be encoded in Haskell:
\begin{verbatim}
data Fin a where 
  FZero :: Fin (Maybe a)
  FSucc :: Fin a -> Fin (Maybe a)

data Lam a where 
  Var :: Fin a -> Lam a
  App :: Lam a -> Lam a -> Lam a
  Abs :: Lam (Maybe a) -> Lam a
\end{verbatim}
Here \texttt{Fin} and \texttt{Lam} are indexed by types instead of
natural numbers; The type constructor \texttt{Maybe} serves as a type level
copy of the $\succ$ constructor for natural numbers.
Note that \texttt{Lam} is actually just a nested datatype 
\cite{alti:csl99} while \texttt{Fin} exploits the full power of
GADTs because the range of the constructors is constrained.

The initial algebra semantics of inductive types can be extended to
model inductive families by replacing functors on the category $\Set$
with functors on the category of families indexed by a given type - in
the case of $\lambda$-terms this indexing type was $\Nat$. The objects
of the category of families indexed over a type $I \in \Set$ are
$I$-indexed families, i.e. functions of type $I\to\Set$, and a
morphism between $I$-indexed families $A,B\in I \to\Set$ is given by a
family of maps $f\in\Pi i \in I.A\,i \to B\,i$. Indeed, this category
is easily seen to be isomorphic to the slice category $\Set/ I$ but
the chosen representation is more convenient type-theoretically. Using
$\Sigma$-types and equality types from Type Theory, we can define the
following endofunctors $F_\Fin$ and $F_\Lam$ on the category of families
over $\Nat$ whose initial algebras are $\Fin$ and $\Lam$, respectively:
\begin{eqnarray*}
  F_\Fin,F_\Lam & \in & (\Nat\to\Set)\to \Nat\to\Set \\
  F_\Fin\,A\,n & = & \Sigma m\in\Nat.(m+1=n) \times (1 + A\,m)\\
  F_\Lam\,A\,n & = & \Fin\,n + A\,n \times A\, n + A\, (n+1)
\end{eqnarray*}
The equality type expresses the focussed character of the
constructors for $\Fin$. 

This approach extends uniformly to more complicated examples such as
the family of typed $\lambda$-terms, using lists of types $[\Ty]$ to
represent typing contexts:
\begin{eqnarray*}
 \Ty & \in & \Set\\
 \Var,\Lam & \in & [\Ty] \to \Ty \to \Set \\
\end{eqnarray*}\vspace{-7ex}

given by the following constructors
\[
\begin{array}{l}
 \ax{\ty \in \Ty}\qquad \ru{\sigma,\tau\in\Ty}{\arr\,\sigma\,\tau\in\Ty}\\
 \ax{\vzero \in \Var\,(\sigma:\Gamma)\,\sigma}
 \qquad
 \ru{x\in \Var\,\Gamma\,\sigma}
 {\vsucc\,x \in \Var\,(\tau:\Gamma)\,\sigma}
 \\
 \ru{x\in\Var\,\Gamma\,\sigma}
 {\var\,x\in\Lam\,\Gamma\,\sigma}
 \quad
 \ru{t\in\Lam\,\Gamma\,(\arr\,\sigma\,\tau)
   \quad u\in\Lam\,\Gamma\,\sigma}
 {\app\,t\,u \in \Lam\,\Gamma\,\tau}
 \\
 \ru{t \in \Lam\,(\sigma:\Gamma)\,\tau}
 {\lam\,t \in \Lam\,\Gamma\,(\arr\,\sigma\,\tau)}
\end{array}\]

\noindent
Types like this can be used to implement a tag-free, terminating
evaluator~\cite{bsn}. To obtain the corresponding functors
is a laborious but straightforward exercise.

\subsection*{Containers}

\noindent The initial algebra semantics is useful to provide a generic
analysis of inductive types exploiting generic concepts such as
constructors and functorial map. However, it cannot say whether such inductive
types actually exist, and it falls short of providing a systematic
characterisation of generic operations such as equality or the
zipper~\cite{huet:zipper,conor:derivative}. 


%  While initial algebra semantics explains the {\em inductive} nature of
% inductive types, and in particular features such as pattern
% matching, recursion combinators, inductive proofs etc, it fails to
% provide proper foundations for datatype generic programming where
% generic functions such as map or equality can be defined by analyzing
% the structure of a given datatype. Further, initial algebra semantics
% tells us nothing about which type expressions correspond to a functors
% which have initial algebras. Finally, it says nothing about the
% polymorphic functions between datatypes generated by such type
% expressions.

% There are a number of syntactic approaches to this problem ---
% \txa{Reformulate!}
% e.g. the use of schemes in COQ --- but there is no definite agreement
% on a solution as is exemplied by the number of proposals. 
In previous
work, \cite{alti:cont-tcs,alti:fossacs03}, we have proposed the notion of a container
type: A (unary) container is given by a set of shapes $S\in\Set$ and a
family of positions $P\in S\to\Set$ assigning, to each shape, the set
of positions where data can be stored in a data structure of that
shape. We write $\cont{S}{P}$ for a container, for example the type of lists
is given by $\cont{\Nat}{\Fin}$ indicating that the shape of a list is
a natural number (its length) and lists of length $n$ have $\Fin\,n$
positions where data is stored. Every container $\cont{S}{P}$ gives rise to a
functor $\llbracket \cont{S}{P} \rrbracket\, X = \Sigma s\in S.P\,s \to X$, and containers are closed under forming products, coproducts,
constant exponentiation and taking initial algebras and terminal
coalgebras which model lazy datatypes. Hence, the theory of containers
also provides a convenient way to express that a category has all
strictly positive datatypes.  We have introduced the notion of a
container morphism and showed that they uniquely capture polymorphic
functions/natural transformations between the functors generated by
the containers. The categorical infrastructure required for this interpretation is
quite modest, it works in any Locally Cartesian Closed category with
finite types (i.e.  an initial object and a disjoint boolean object)
and W-types.

While containers provide an elegant foundation for generic programming
with inductive types, in this paper we will develop the theory of
\emph{indexed containers} which allows us to provide a similar
foundation for programming with inductive families like $\Fin$ and
$\Lam$. Our results give us the best of both worlds in that the theory
of ordinary containers carries over to the more expressive indexed
setting, e.g. we can again establish a notion of container morphism
such that the interpretation functor is full and faithful. Maybe most
surprisingly all this additional expressivity comes for free, as far
as the type-theoretic infrastructure is concerned --- W-types are
still enough.

\subsection*{Main results}

\noindent We introduce the notion of indexed container which
generalizes containers allowing us to represent inductive
families. This is a further step from \emph{dependent polynomial
  functors} \cite{HylandGambino} representing endofunctors on a slice
category. Indexed containers as introduced in the present paper allow us
to represent functors between different slices and capture also mutual
and nested inductive definitions.

While Hyland and Gambino \cite{HylandGambino} show that dependent polynomial 
functors always
have initial algebras, we show that indexed containers are closed under 
parametrized initial algebras. Hence we can apply the fixpoint
construction several times. The flexibility of indexed
containers allows us to also establish closure under the adjoints of
reindexing. This leads directly to a grammar for strictly positive
families, which itself is an instance of a strictly positive family 
(section \ref{sec:spf}) --- see also our previous work \cite{alti:cats07,alti:jcats07}.

Our presentation here uses type theoretic notation while our own
previous work on containers and the work on dependent polynomial functors used
categorical notions. While Type Theory can be more bureaucratic in places, it
leads directly to an implementation in a dependently typed programming
language. This is witnessed by our formalisation of the main results
of this paper in Agda (available online~\cite{agdaform}).

 % In
% our present paper we reconstruct and generalize their results in a
% type-theoretic setting: we show closure under \emph{parametrized
%   initial algebras} which allows us to construct mutually defined
% inductive families, we define a notion of morphisms between indexed
% containers and extend our representation theorem to the indexed
% setting, show that indexed containers are closed under a number of
% semantic constructions and exploit this to provide a grammar of
% indexed inductive types.

\subsection*{Related Work}
\label{sec:related-work}

\noindent We have already discussed the relation to our own work on containers
and strictly positive families and to dependent polynomial functors.

Containers are related to Girard's normal functors \cite{GirardNormal} which
themselves are a special case of Joyal's analytic functors
\cite{JoyalA:fonaes} --- those that allow only finite sets of positions.
Fiore, Gambino, Hyland and Winskel's work on generalized species
\cite{fiore2008ccb} considers those concepts in a more generic setting ---
th e precise relation of this work to indexed containers remains to be
explored.

\noindent Perhaps the earliest publication related to indexed containers
occurs in Petersson and Synek's paper
\cite{PS89} from 1989. They present rules extending Martin-L{\"o}f's
type theory with a set constructor for `tree sets' : families of
mutually defined inductive sets, over a fixed index set.

\noindent Inspired in part by Petersson and Synek's constructor,
Hancock, Hyvernat and Setzer \cite{hancock-apal06} applied indexed (and unindexed)
containers, under the name `interaction structures' to the task of
modelling imperative interfaces such as command-response interfaces in
a number of publications. 

\subsection*{Acknowledgments}
\label{sec:acknowledgements}

\noindent The present paper grew out of previous joint work with Neil
Ghani, Peter Hancock and Conor McBride. Neil Ghani provided very
elegant proofs of propositions \ref{prop:extfull} and
\ref{prop:adjoints}.  We profited greatly from comments and feedback from our
colleagues in the Functional Programming Laboratory in Nottingham.

\section{Type theoretic preliminaries}

\noindent We work in an extensional
% \footnote{Our construction doesn't rely on the equality reflection rule but can be formalized in an intensional Type Theory with an extensional propositional equality such as Observational Type Theory \cite{alti:ott-conf}.}
Type Theory \cite{martinlof:itt} 
with the following ingredients:
\begin{description}
\item[$\Set_i$] A cumulative hierarchy of universes $\Set_i\inx\Set_{i+1}$ for
  $i\in\Nat$, cumulativity means that $A\in\Set_i$ implies
  $A\in\Set_{i+1}$. We will omit the indices in our development 
  pretending that $\Set\in\Set$ but making sure that all our definitions
  can be stratified.

\item[$0,1$] An empty type $0\in\Set_i$ and a unit type
  $1\in\Set$. Categorically, those correspond to initial and
  terminal objects. For any set $A$ we write $?_A \in 0 \to A$ for the
  unique map of this type. We write $() \in 1$ for the unique
  inhabitant of $1$ and $!_A \in A \to 1$ with $!_A\,a = ()$ for the
  unique map into $1$. 

\item[$2$] A type of Booleans $2\in\Set_i$, which is disjoint, i.e. we
  have that $(\mathrm{true} = \mathrm{false})\to 0$ is inhabited. 

\item[$\Sigma$- and $\Pi$-types] 

\item[]  Given $A\in\Set_i$ and $B\in\Set_i$
  given that $x\in A$ then $\Sigma x\inx A.B, \Pi x\inx A.B \in \Set_i$.
  Elements of $\Sigma$-types are pairs, if $a\in A$ and $b\in B[x:=a]$
  then $(a,b) \in \Sigma x\in A.B$, while elements of $\Pi$-types are
  functions: given $b\in B$ assuming $x\in A$ then $\lambda x.b \in
  \Pi x\inx A.B$% 
  \footnote{We use untyped $\lambda$-abstraction and make sure that
    the type can be inferred from the context.}.

\item[Equality types] 

\item[]  Given $a,b\in A \in \Set_i$ we write $a = b \in
  \Set_i$ for the equality type. The constructor for equality is
  reflexivity $\refl\,a \in a=a$ if $a\in A$. 

\item[$\WW$-types] 

\item[]  As for $\Sigma$ and $\Pi$ Given $A\in\Set_i$ and
  $B\in\Set_i$ given that $x\in A$ then $\WW\,x\inx A.B \in \Set_i$.
  The elements of a $\WW$-type are well-founded trees which are
  constructed using $\sup$: if $w\in\Sigma x\inx A.B\to \WW\,x\inx A.B$ 
  then $\sup\,w \in \WW x\inx A.B$
\footnote{Usually the type of $\sup$ is curried and $\sup$ has two
  arguments instead. This version is more convenient for our purposes.}.
\end{description}
We omit a detailed treatment of eliminators and use functional
programming notation, like if-then-else, dependently typed pattern
matching and structural recursion as present in Agda and Epigram.
All our definitions can be translated into the standard
eliminators at the price of readability.
\txa{Evidence by formalizing in Agda instead?}
To avoid clutter we adopt the usual type-theoretic device of allowing
hidden arguments, if they are inferable from the use. We indicate
hidden arguments by subscripting the type, i.e. writing $\Pi_{x\in
  A}B$ and $\Sigma_{x\in A}B$ instead of $\Pi x\in A.B$ and 
$\Sigma x\in A.B$.

If we ignore the predicative hierarchy, the categorical infrastructure
corresponds to Locally Cartesian Closed category, with initial
objects, a disjoint boolean object and initial algebras for 
functors of the form 
\[F_{\WW x\in A.B} X = \Sigma x\in A.B\to X \]

While finite products arise as non-dependent $\Sigma$-types, finite
coproducts can be represented as
\[ A + B = \Sigma b\in
2. \mathrm{if}\,b\,\mathrm{then}\,A\,\mathrm{else}\,B\] 
Given $f \in A \to C, g \in B \to C$ we define
\begin{align*}
  & \mathrm{case}\,f\,g \in A+B\to C\\
  & \mathrm{case}\,f\,g\,(b,x) =
\mathrm{if}\,b\,\mathrm{then}\,(f\,x)\,\mathrm{else}\,(g\,x)
\end{align*}
Replacing
$\Sigma$ by $\Pi$ this also gives rise to an alternative way to define
$\times$. 

% We can also encode the dual of $\WW$-types, i.e. the
% terminal coalgebra of the same $F_\WW$ which we dub M-types using a
% limit-like construction, see \cite{jcontainer}.

\txa{M-types ?}


\section{Indexed functors}
\label{sec:indexed-functors}

\noindent Given $I\in\Set$ we consider the category of families over
$I$. It's objects are families of types $A\in I\to\Set$ and given 
$A,B\in I\to\Set$ a morphism $f$ is a family of functions
$f\in \Pi_{i\in I}A\,i\to B\,i$, identity and composition are
obvious. We denote this category as $\Fam\,I$. Indeed $\Fam\,I$ is
isomorphic to the slice category $\Set/I$ whose objects are morphisms
$J \to I$ for some $J\in\Set$ and whose morphisms are commuting
triangles.

An indexed functor over $I\in\Set$ is a functor from $\Fam\,I$ to
$\Set$, to make this precise an indexed functor $F$ is given by
\begin{eqnarray*}
  \obj{F} & \in & (I \to \Set) \to \Set\\
  \mor{F} & \in & \Pi_{A,B\in I\to\Set}(\Pi_{i\in I} A\,i \to B\,i)
  \to F\,A \to F\,B
\end{eqnarray*}
subject to the conditions that $\mor{F}$ preserves identity and
composition. As usual we omit the annotations when the meaning is
clear from the context and overload $F$ to mean $\obj{F}$ and
$\mor{F}$. 

Given two indexed functors $F,G$ a family of maps 
\[ \alpha \in \Pi A\in I\to\Set.F\,A \to G\,A\] is a natural
transformation, if the naturality condition 
($G\, f \circ \alpha\, A = \alpha\,B\circ F\,f$ for $f\in \Pi_{i\in I} A\,i \to B\,i$)
holds. 
We write $F \nattfn G$ for the set of
natural transformations and $\Func\,I$ for the category of
indexed functors and natural transformations.

$\Func$ comes with a monad-like structure, we have
\begin{align*}
& \returnF \in I \to \Func\,I\\  
& \returnF\,i\,A = A\,i
\end{align*}
and given $F\in \Func\,I$ and $H\in I\to\Func\,J$ we construct
\begin{align*}
& F \bindF H \in \Func\,J \\
& (F \bindF H)\,A = F\,(\lambda i.H\,i\,A)
\end{align*}
it is easy to see that the usual equations for a monad hold. It is not
actually a monad since $\Func : \Set_i \to \Set_{i+1}$ is not closed
at any level.
\footnote{The situation is similar as in \cite{alti:csl99} where we called this a \emph{Kleisli structure}.}
% . $\Func$ is, however, a monoid in the category of endofunctors
% from $\Set_i$ to $\Set_{i+1}$.

The opposite of the Kleisli category associated to $\Func$ has as
objects sets $I,J\in \Set$ and morphisms given by an $J$-indexed
family of $I$-indexed functors.  We overload $\Func$ and write
$\Func\,I\,J = J \to \Func\,I$. We use the opposite of the Kleisli
category so that $F\in \Func\,I\,J$ is a functor from $\Fam\,I$ to
$\Fam\,J$. Indeed given $A\in \Fam\,I$ we write:
\begin{gather*}
  F @ A \in \Fam\,J\\
  (F @ A)\,j = F\,j\,A
\end{gather*}
This construction also extends to natural transformations,
i.e. the set of natural transformation between $F,G \in \Func\,I\,O$
is given by $\Pi o\in O.F\,o \nattfn G\,o$.
% Kleisli categories inherit products
% from the underlying category and hence $\Func$ has finite products
% given by coproducts in $\Set$.

There are several operations which we can use to construct indexed
functors. Clearly the Kleisli structure gives identities and
composition in $\Func$. Assuming $f\in O\to O'$, reindexing 
is defined by composition:
\begin{align*}
  & \FDelta\,f \in \Func\,I\,O' \to \Func\,I\,O\\
  & \FDelta\,f\,F = F \circ f
\end{align*}
Notice the contravariance in the above definition which is to be
expected of reindexing. An example of the use of
reindexing occurs in the definition of the indexed functor whose
fixed point is $\Lam$ where we need to turn an indexed functor $F$
into an indexed functor $F'$ defined by $F'\,n\,X = F\,(n+1)\,X$. In
this situation, $F'$ is just $\FDelta\,(+1)\,F$.

Unsurprisingly, $\FDelta\,f$ has both left and right adjoints, those
are given by 
\begin{align*}
  &\FSigma\,f,\FPi\,f \in \Func\,I\,O \to \Func\,I\,O'\\
  &\FSigma\,f\,F = \lambda X,o.\Sigma o'\in O'.f\,o = o' \times
  F\,X\,o'\\
  &\FPi\,f\,F = 
  \lambda X,o.\Pi o'\in O'.f\,o = o' \to
  F\,X\,o'
\end{align*}
$\FSigma$ is used in the construction of $F_\Fin$:
\begin{gather*}
F_\Fin = F\,\mathrm{succ}\,(\lambda A\,m.1 + A\,m)
\end{gather*}
Finite coproducts and products of indexed functors arise as special
cases of $\FSigma$ and $\FPi$. Given $F,G \in \Func\,I$ we construct
\begin{align*}
  &H_0 \in \Func\,I\,0\\
  &H_0 = ?_{\Func\,I}\\
  &H_2 \in \Func\,I\,2\\
  &H_2 = \lambda b.\mathrm{if}\,b\,\mathrm{then}\,F\,\mathrm{else}\,G 
\end{align*}
Using the family of unique forgetful functions $!_A\in A \to 1$ we obtain
\begin{align*}
  &\FK_0,F \Fplus G, \FK_1, F\Ftimes G \in \Func\, I\,1 \simeq \Func\,I\\
  &\FK_0 = \FSigma\,!_0\,H_0\\
  &F \Fplus G = \FSigma\,!_2\,H_2\\
  &\FK_1 = \FPi\,!_0\,H_0\\
  &F \Ftimes G = \FPi\,!_2\,H_2
\end{align*}
More concretely $\FK_0,\FK_1$ are simply the constant functors
returning $0$ (resp. $1$), and $F\Fplus G$ and $F\Ftimes G$ are the point-wise
coproducts (resp. coproducts) of $F$ and $G$. The reduction to $\FSigma$ and 
$\FPi$ means we don't have to explain the behaviour of these constructs, it
is inherited.

In the examples we only used finite products, the more general case of
$\FPi$ is relevant when we define infinitely branching trees.

\section{Initial algebras of indexed functors}
\label{sec:init-algebr-index}

\noindent Given an indexed endofunctor $F\in \Func\,I\,I$ we can apply the usual
notion of initial algebra, To spell it out: an $F$-algebra $(A,a)$ is a
family $A:\Fam\,I$ together with a function in $\Fam\,I$:
$a:\Pi_{i\in I}(F @ A)\, i \to A\, i$. Given $F$-algebras $(A,a)$ and
$(B,b)$ a morphism is a function $f:\Pi_{i\in I}A\, i \to B\, i$ s.t.
\[
\xymatrix{
F @ A  \ar[r]^{a} 
\ar[d]_{F @ f} & A \ar[d]^{f}\\
F @ B \ar[r]^{b} & B}
\]
An initial $F$-algebra $(\mu^0\,F,\inn)$  is the initial object in this category, if it exists.
Initial algebras of functors don't always exist as we already know
from the non-indexed case (which arises as a special case of indexed
functors where $I=1$). For example the functor $F\in \Set \to \Set$
given by $F\,A = (A \to 2) \to 2$ hasn't got an initial algebra in a
predicative theory.

We can apply the initial algebra construction only once, because it takes us from 
an indexed functor $F\in \Func\,I\,I$ to the category of families
$\mu^0\,F\in\Fam\,I$. Hence we can't define nested or mutual inductive families.
To overcome this we introduce parametrized initial objects.

Coproducts of indexed functors correspond to indexed functors on the product of
slices, i.e. just by looking at the object part:
\begin{align*}
& \Func\,(I+J)\\
& = (I + J \to \Set) \to \Set \\
& \simeq (I \to \Set) \times (J \to \Set) \to \Set
\end{align*}
We can curry the last line:
\begin{align*}
& \simeq (I \to \Set) \to (J \to \Set) \to \Set
\end{align*}
This gives rise to partial application of an indexed functor which we
will employ in our definition of parametrized initial
algebras.
\begin{align*}
&\ru{\begin{array}{l}F \in \Func\,(I+J)\,J \\
  G \in \Func\,I\,J\end{array}}
{F[G] \in \Func\,I\,J}\\
\\
&F[G]\,j\,A = F\,j\,(\mathrm{case}\,A\,(G @ A))
\end{align*}
This definition is functorial, i.e. given $\alpha \in G \nattfn H$
we obtain $F[\alpha] \in F[G] \nattfn F[H]$.

Given $F\in \Func\,(I+J)\,J$ a parametrized $F$-algebra is given by 
an indexed functor $G\in\Func\,I\,J$ and a natural transformation
$\alpha \in F[G] \nattfn G$. A morphism between two parametrized
$F$-algebras $(G,\alpha)$ and $(H,\beta)$ is a natural
transformation $\gamma \in G \nattfn H$ such that 
\[
\xymatrix{
F[G]  \ar[r]^{\alpha} 
\ar[d]_{F[\gamma]} & G \ar[d]^{\gamma}\\
F[H] \ar[r]^{\beta} & H}
\]
The parametrized initial algebra of $F$, i.e. the initial object in
the category of parametrized $F$-algebras, we denote by
$(\mu^I\,F,\inn_F)$, if it exists. The special case of $I=0$
corresponds to non-parametrized algebras.

\section{Indexed containers}
\label{sec:indexed-container}

\noindent Given $I\in\Set$ we define the category $\Cont\,I$ of indexed
containers over $I$, together with an extension functor $\ExtC{-}\in
\Cont\,I\to\Func\,I$. While an ordinary container is a pair of a set
of shapes and a family of positions indexed by shapes, an indexed
container also consists of a set of shapes
\begin{gather*}
  S \in \Set
\end{gather*}
and a family of positions indexed by shapes and the indexing set $I$:
\begin{gather*}
  P\in S\to I \to\Set.
\end{gather*}
We denote this container as
\[\cont{S}{P}\in\Cont\,I.\] 
Its extension is given as:
\begin{align*}
& \ExtC{\cont{S}{P}} \in \Func\,I\\  
& \obj{\ExtC{\cont{S}{P}}}\,A = \Sigma s\in
  S.\Pi_{i\in I}P\,s\,i \to A\,i\\
& \mor{\ExtC{\cont{S}{P}}}\,f\,(s,h) = (s,\lambda i\in I.f\,i \circ h\,i)  
\end{align*}
Given indexed containers
$\cont{S}{P},\cont{T}{Q}\in \Cont\,I$ a container morphism is given by
a function on shapes 
\[ f\in S\to T \] 
and an $I$-indexed contravariant
function on positions 
\[r\in\Pi_{s\in S,i\in I}Q\,(f\,s)\,i\to P\,s\,i.\] 
We write the morphism as 
\[\cont{f}{r}\in \Cont\,I\,(\cont{S}{P})\,(\cont{T}{Q}) \]
The extension of a container morphism is a
natural transformation between the associated functors given by:
\begin{align*}
& \ExtC{\cont{f}{r}} \in
  \Pi X\in I\to\Set.\ExtC{\cont{S}{P}}\,X \to \ExtC{\cont{T}{Q}}\,X\\
& \ExtC{\cont{f}{r}}\,X\,.(s,h) = (f\,s,\lambda q.h\,(r\,q))
\end{align*}
As for ordinary containers (see \cite{alti:cont-tcs}) we can show 
\begin{proposition}\label{prop:extfull}
  The extension functor $\ExtC{-}\in\Cont\,I\to\Func\,I$ is full and faithful.
\end{proposition}

We will now lift the operations we have previously defined on indexed
functors to indexed containers. However, as we will see -- unlike indexed
functors -- indexed containers always admit initial algebras. We start
with identifying the monadic structure on $\Cont$ which is preserved
by $\ExtC{-}$:
\begin{align*}
  & \returnC \in I \to \Cont\,I \\
  & \returnC\,i = (1,\lambda s,j.i=j)
\end{align*}
Given 
$H = \lambda i.\cont{S\,i}{P\,i}\in I\to\Cont\,J$ with $S\in I\to
\Set$ and $P\in\Pi i\in I.S\,i\to J\to\Set$ and $\cont{T}{Q}\in \Cont\,I$:
\begin{align*}
& \cont{T}{Q} \bindC H \in \Cont\,J \\
& (\cont{T}{Q} \bindC H) = \cont{U}{R}\\
&\quad\mathrm{with}\;\;\\
&\quad\;\; U \in \Set \\
&\quad\;\; U = \ExtC{\cont{T}{Q}}\,S \\
&\quad\;\; R \in U \to I \to \Set \\
&\quad\;\; R\,(t,f)\,i = \Sigma q\in Q\,t\,i,j\in J.P\,i\,(F\,i\,q)\,j
\end{align*}
The operations satisfy the monadic laws, modulo the change in universe level,
as in the monadic structure on indexed functors. Moreover,
the monadic structure is preserved by the extension
operation. 

As in the case of $\Func$ this gives rise to the category $\Cont$,
whose objects are sets $I,J\in\Set$ and morphisms are 
$\Cont\,I\,J = J \to \Cont\,I$. We will exploit that the elements of 
$\Cont\,I\,J$ can be isomorphically represented as a pair:
\begin{gather*}
  \vec{S} \in J \to \Set\\
  \vec{P} \in \Pi_{j\in J}\vec{S}\,j \to I \to \Set
\end{gather*}
and write $\cont{\vec{S}}{\vec{P}} \in \Cont\,I\,J$.

The definition of reindexing carries
over without change from indexed functors, i.e. given $f\in O\to O'$, we define 
$\CDelta\,f \in \Cont\,I\,O' \to \Cont\,I\,O$ by $\CDelta\,f\,F = F \circ f$
Moreover, we can define its adjoints on indexed containers:
\begin{align*}
  &\CSigma\,f,\CPi\,f & \in & \Cont\,I\,O \to \Cont\,I\,O'\\
  &\CSigma\,f (\cont{\vec{S}}{\vec{P}})
  & = &\lambda o.\Sigma o'\in O'.f\,o = o' \times \vec{S}\,o'\\
  && \lhd &\lambda o,(\_,\_,s).P\,s\\
  & \CSigma\,f (\cont{\vec{S}}{\vec{P}})
  & = & \lambda o.\Pi_{o'\in O'}f\,o = o' \to \vec{S}\,o' \\
  &&\lhd & \lambda o,g. \Sigma o\in O,e\in f\,o = p,\vec{P}\,(g\,e)
\end{align*}
It is easy to see that $\ExtC{\CSigma\,f\,(\cont{S}{P}} \simeq
\FSigma\,f\,\ExtC{\cont{S}{P}}$ and 
$\ExtC{\CPi\,f\,(\cont{S}{P})} \simeq
\FPi\,f\,\ExtC{\cont{S}{P}}$ and using proposition \ref{prop:extfull} we can conclude
\begin{proposition}\label{prop:adjoints}
  Reindexing of indexed containers $\CDelta\,f$ has left and right adjoints
  \[ \CSigma\,f \vdash \CDelta\,f \vdash \CPi\,F \]
  and this structure is preserved by $\ExtC{-}$.
\end{proposition}
Using the construction in section \ref{sec:indexed-functors} this entails that
indexed containers are closed under coproducts and products.

\section{Initial algebras of containers}
\label{sec:initial-algebras}

\hyphenation{endo-functor}

\noindent An indexed container $\cont{\vec{S}}{\vec{P}}\in\Cont\,I\,I$ denotes
an endofunctor on $\Fam\,I$. Unlike for functors in general, initial
algebras of indexed containers always exist. While the initial algebra
of an ordinary unary container $\cont{S}{P}$ is given by the W-type 
$\WW\,x\in S.P\,s$, the initial algebra of an indexed container is
given by an indexed generalisation of W-types. That is given
\begin{gather*}
  \vec{S} \in I\to\Set\\
  \vec{P} \in I\to\Pi_{i\in I}\vec{S}\,i \to I \to \Set
\end{gather*}
we define
\begin{gather*}
  \WW^I\,\vec{S}\,\vec{P} \in I \to \Set
\end{gather*}
as inductively generated by
\[
\ru{(s,f) \in \Sigma s\in \vec{S}\,i . \Pi_{i'\in I} 
  \vec{P}\,s\,i' \to \WW^I\,\vec{S}\,\vec{P}\,i'}
{\sup^I\,(s,f) \in \WW^I\,\vec{S}\,\vec{P}\,i}
\]
or with other words $ \WW^I\,\vec{S}\,\vec{P}$ is the initial algebra
of $\ExtC{\cont{S}{P}}$. An interesting observation is that $\WW^I$
can be constructed from ordinary $\WW$-types. The idea is to define an
approximation of $\WW^I$ as an ordinary $\WW$ type, namely 
\[\WW \,(i,s)\inx (\Sigma i\in I.\vec{S}\,i). 
  (\Sigma i'\in I.\vec{P}\,s\,i')\]
and then to identify the good trees by
\emph{type-checking}. Variants of this
construction can be found in \cite{alti:cont-tcs} and \cite{HylandGambino}. 

% To construct $\WW^I$, we first approximate the correct type by an ordinary
% W-type and then identify the correct trees by \emph{type checking}.
% The approximation is given by $\WW\,\hat{S}\,\hat{P}\in\Set$ where
% \begin{eqnarray*}
%   \hat{S} & \in & \Set \\
%   \hat{S} & = & \Sigma j\in J.\vec{S}\,j \\
%   \hat{P} & \in & \hat{S} \to \Set \\
%   \hat{P}\,(j,s) & = & \Sigma j'\in J.\vec{P}\,s\,j'
% \end{eqnarray*}

% We now define two functions by primitive recursion on
% $\WW\,\hat{S}\,\hat{P}$, one $\down$ which labels a tree with the
% indizes we expect and another one $\up$ which labels a tree with the
% indizes which are given. 
% \begin{eqnarray*}
%   \down & \in & \WW\,\hat{S}\,\hat{P} \to J \to \WW\,(\hat{S}\times
%   J)\,(\hat{P}\circ\pi_1)\\
%   \down\,(\sup\,s\,f)\,j & = & \sup\,(s,j)\,\lambda
%   (j',p).\down\,(f\,(j',p))\,j'\\
%   \\
%   \up & \in & \WW\,\hat{S}\,\hat{P} \to \WW\,(\hat{S}\times
%   J)\,(\hat{P}\circ\pi_1)\\
%   \up\,(\sup\,(j,s)\,f) & = & \sup\,((j,s),j)\,\lambda p.\down\,(f\,p)
% \end{eqnarray*}
% The good trees are now the ones where both functions agree,
% initializing $\down$ with the index we want to see on the top. 
% \begin{eqnarray*}
%   \WW^J & \in & J\to\Set \\
%   \WW^J\,j & = & \Sigma w\in \WW\,\hat{S}\,\hat{P}.\down\,w\,j =
%   \up\,w
% \end{eqnarray*}
% The property that a tree type checks is hereditary, i.e. given $f \in
% \Pi_{j'\in J} P\,s\,j' \to \WW^j\,j$ if it holds
% for all subtrees $g\in \Pi_{j'\in J}p\in P\,s\,j'.\down\,(f\,p)\,j' =
%   \up\,(f\,p)$ then the whole tree type checks, i.e. we have
% $\he\,g \in \down\,(\sup\,(s,f))\,j = \up\,(\sup\,s\,f)$. Using this
% we can complete the construction by providing $\sup^J$:
% \begin{eqnarray*}
%     \sup^J & \in & \Pi_{j\in J} F_{\WW^J}\,j\,(\WW^J\,S\,P) \to
%   \WW^J\,S\,P\,j\\
%   \sup^J_j\,s\,f & = & (\sup\,(j,s)\,\pi_1\circ f,\he\,(\pi_2\circ f))
% \end{eqnarray*}
% \txa{Sketch construction of $\WW^I$, refer to Hyland & Gambino}

\begin{proposition}
  $(\WW^I\,\vec{S}\,\vec{P},\sup_I)$, i.e. the initial algebra of
  $\ExtC{\cont{\vec{S}}{\vec{P}}}$ can be constructed from $\WW$-types using
  $\Pi$, $\Sigma$ and equality types. Equivalently it exists in any
  Martin-L\"of category (Locally Cartesian Closed category with $\WW$-types).
\end{proposition}

We are going to generalize this result to parametrized initial
algebras. We first define partial application, given 
\begin{gather*}
  \cont{\vec{S}}{\vec{P}} \in \Cont\,(I+J)\,J\\
  \cont{\vec{T}}{\vec{Q}} \in \Cont\,I\,J
\end{gather*}
with 
\begin{gather*}
  \vec{S} \in J\to\Set\\
  \vec{P} \in \Pi_{j\in J} \vec{S}\,j \to I+J \to \Set\\
  \vec{T} \in J\to\Set\\
  \vec{Q} \in \Pi_{j\in J} \vec{T}\,j \to I \to \Set
\end{gather*}
we define
\begin{gather*}
  \cont{\vec{S}}{\vec{P}}[\cont{\vec{T}}{\vec{Q}}] = \cont{\vec{U}}{\vec{R}}\\
  \in \Cont\,I\,J
\end{gather*}
We observe that we can separate the $I$- and $J$-indexed positions of $\vec{P}$ by case analysis, giving rise to
\begin{gather*}
  \vec{P}^I \in \Pi_{j\in J} \vec{S}\,j \to I \to \Set\\
  \vec{P}^J \in \Pi_{j\in J} \to \vec{S}\,j \to J \to \Set\\
\end{gather*}
Clearly $\cont{\vec{S}}{\vec{P}^J} \in \Cont\,J\,J$ is a container,
and we can use its extension to construct the shapes of the resulting
container:
\begin{gather*}
  \vec{U} \in J\to\Set \\
  \vec{U} = \ExtC{\cont{\vec{S}}{\vec{P}^J}} @ \vec{T}
\end{gather*}
We also express the construction of the positions parametrically, using
\begin{gather*}
  \diamond\,\vec{Q} \in \Pi_{j\in J} \vec{U}\,j \to I \to \Set\\
  \diamond\,\vec{Q}\,(s,f)\,i = \vec{P}^I\,s\,i +
  \Sigma_{k\in J}\Sigma p\in \vec{P}^J\,s\,k.\vec{Q}\,(f\,p)\,i
\end{gather*}
This represents the possible positions in the combined container which
are either top-level positions ($\vec{P}^I$) or positions inside the
second container given by a top-level ($\vec{P}^J$) position combined with a 
position in $\vec{Q}$ of the appropriate shape. Hence we set:
\begin{gather*}
  \vec{R} \in \Pi_{j\in J} \vec{U}\,j \to I \to \Set\\
  \vec{R} = \diamond\,\vec{Q}
\end{gather*}
As expected this construction is functorial: on shapes we exploit the
morphism part of $\ExtC{\cont{\vec{S}}{\vec{P}^J}}$. To construct the 
position part of the morphism we exploit that $\diamond$ is an indexed 
functor itself and it commutes with $\ExtC{\cont{\vec{S}}{\vec{P}^J}}$, i.e.
\begin{gather*}
  \diamond\,\vec{Q'}\,(\ExtC{\cont{\vec{S}}{\vec{P}^J}}\,f\,x)
  = \diamond\,(\vec{Q'}\circ f)\,x
\end{gather*}

We are going to reuse those components in the construction of the
parametrized initial algebra of $\cont{\vec{S}}{\vec{P}}$ above:
\begin{gather*}
  \mu^I = \cont{\vec{U}_\mu}{\vec{R}_\mu}\\
  \in \Cont\,I\,J
\end{gather*}
The shapes are the trees which can be constructed using 
$\ExtC{\cont{\vec{S}}{\vec{P}^J}}$, hence
\begin{gather*}
  \vec{U}_\mu \in J \to \Set\\
  \vec{U}_\mu = \WW^J\,\vec{S}\,\vec{P}^J
\end{gather*}
The positions are the paths in the resulting trees which can be constructed 
using structural recursion of the indexed W-type:
\begin{gather*}
  \vec{R}_\mu \in \Pi_{j\in J} \vec{U}_\mu\,j \to I \to \Set\\
  \vec{R}_\mu\,(\sup^J\,(s,f)) = \diamond\,\vec{R}_\mu\,(s,f) 
\end{gather*}
We are ready to define the constructor, i.e. the morphism part of the
parametrized initial algebra:
\begin{gather*}
  \inn = \cont{f}{r} \\
  \in \Cont\,(\cont{\vec{S}}{\vec{P}}[\mu^I])
  \,\mu^I
\end{gather*}
Clearly, the shape component is just the constructor for $\WW_J$:
\begin{gather*}
  f \in \Pi_{j\in J}(\ExtC{\cont{\vec{S}}{\vec{P}^J}}@ \vec{U}_\mu)\,j \to \vec{U}_\mu\,j\\
  f = \sup^J
\end{gather*}
The morphism on positions is simply the identity, because we can exploit the recursive definition of $\vec{R}_\mu$:
\begin{gather*}
  r \in \Pi_{j\in J,i\in I}\Pi (s,f) \in \vec{U}_\mu\,j.\vec{R}_\mu\,(\sup^J\,(s,f)\,i \to \diamond\,\vec{R}\,u\,i\\
  r\,(s,f)\,r = r
\end{gather*}
The definition of fold is straightforward, it is basically forced upon us and hence unicity holds. We summarize:
\begin{proposition}
  $(\mu^I,\inn)$ is the parametrized initial algebra of $\ExtC{\cont{\vec{S}}{\vec{P}}}$.
\end{proposition}

\section{Strictly positive families}
\label{sec:spf}

Finally, we will define a syntactic representation of strictly
positive families, which itself is a strictly positive indexed
family.  Given $J\in\Set$ we
define $\SPF\in I\to\Set$ inductively. As before for $\Func$ and
$\Cont$ we define $\SPF\,I\,J = J \to \SPF\,I$. This notation will
subsequently be justified by establishing that $\SPF$ is monadic and
hence gives rise to a category of strictly positive families. 
\[
\ru{i\in I}{\returnT\,i\in\SPF\,I}
\]
\[
\ru{O'\in\Set \quad f\in O' \to O\quad F \in \SPF\,O'\,I}
{\begin{array}{c}\TPi\,f\,F\in \SPF\,I\,O\\
\TSigma\,f\,F\in \SPF\,O\,J\end{array}}
\]\[
\ru{F\in\SPF\,(I+J)\,J}{\Tmu\,F\in\SPF\,I\,J}
\]
As before $\SPF\,I\in\Set_{i+1}$ if $I\in\Set_i$ because the
constructors $\TSigma,\TPi$ are indexed by a set which should live on
the same level as the index. Ignoring size again, $\SPF$ is monadic,
$\returnT$ is a constructor. Given $G\in \SPF\,I$ and 
$F\in I \to \SPF\,J = \SPF\,J\,I$
we define $G \bindT F \in\SPF\,J$ recursively over $G$:
\begin{gather*}
  (\returnT\,i) \bindT F = F\,i\\
  (\TPi\,f\,G\,j) \bindT F = \TPi\,f\,(F\circ G) )\,j\\
  (\TSigma\,f\,G\,j) \bindT F = \TSigma\,f\,(F\circ G) )\,j\\
  (\Tmu\,G\,j) \bindT F = \Tmu\,(G\circ \SPF\,\inl)\,j
\end{gather*}
Here $F\circ G = \lambda o.(G\,o)\bindT F$ is the derived composition
operation and $\SPF\,f \,G = (\returnT\circ f) \bindT G$ is the action of the
SPF functor on morphisms. In this
presentation the algorithm isn't structurally recursive but this can
be addressed by in-lining the weakening ($\SPF\,\inl$) along the lines of 
\cite{alti:csl99}.

It is straightforward to define an interpretation of the syntax as
indexed containers, that is given $A\in\SPF\,I$ we obtain
$\ExtT{A}\in\Cont\,I$. As before this automatically extends to
morphisms: given $F\in\SPF\,I\,J$ we obtain $\ExtT{F}\in\Cont\,I\,J$.
\begin{eqnarray*}
  \ExtT{\returnT\,i} & = & \returnC\,i \\
  \ExtT{\TPi\,f\,G\,j} & = & \CPi\,f\,\ExtT{G}\,j\\
  \ExtT{\TSigma\,f\,G\,j} & = & \CSigma\,f\,\ExtT{G}\,j\\
  \ExtT{\Tmu\,G\,j} & = & \Cmu\,\ExtT{G}\,j
\end{eqnarray*}
The monadic structure is preserved by the interpretation function.

By combining $\ExtT{-}$ and $\ExtC{-}$ we obtain an interpretation of
indexed types as indexed functors $\ExtF{-} \in \SPF\,I\to\Func\,I$.
Note that it is necessary to go via indexed containers, since -- as we
have remarked earlier -- functors are not necessarily closed under initial
algebras.

As an example we encode $\Fin$ and $\Lam$ as strictly positive
families exploiting the construction of finite coproducts and
products in the syntax:
\begin{align*}
  &\Fin^T, \Lam^T \in \SPF\,0\,\Nat\\
  &\Fin^T = \Tmu\,(\lambda n.\TSigma\,\succ\,\TK_0\,n 
  \Tplus \TSigma\,\succ\,(\returnT \circ \inr))\\
  &\Lam^T = \Tmu\,(\lambda n.(\Fin^T \circ (\SPF\,\inl))\,n\\
  &\qquad \Tplus \returnT\,(\inr\,n) \Ttimes \returnT\,(\inr\,n)\\
  &\qquad \Tplus \returnT\,(\inr\,(\succ\,n)))
\end{align*}

\section{Conclusions and further work}
\label{sec:concl-furth-work}

We have shown how inductive families, a central feature in dependently
typed programming, can be constructed from the standard infrastructure
present in Type Theory, i.e. W-types together with $\Pi$, $\Sigma$ and
equality types. Indeed, we are able to reduce the syntactically rich
notion of inductive families to a small collection of categorically
inspired combinators. This is an interesting alternative to the
complex syntactic schemes present in the \emph{Calculus of Inductive
  Constructions} (CIC), or in the Agda and Epigram systems. We are
able to encode inductively defined families in a small core language
which means that we rely only on a small trusted code base. The
reduction to $\WW$-types requires an extensional propositional
equality --- our recent work on \emph{Observational Type Theory} (OTT) 
\cite{alti:ott-conf} shows that this is not an obstacle to implementation.

Central to our construction is the notion of indexed containers
generalizing both simple containers and dependent polynomial functors. 
Indexed containers, like simple containers, are closed under an initial
algebra construction and like dependent polynomial functors model
inductive families. We were able to exploit recent progress in the
implementation of the Agda system to give a certified implementation
of our main results closely following the high level structure of our
construction. We decided not to base our presentation on the
formalisation to be able to ignore irrelevant details of the actual
formalisation and provide a better narrative.

We haven't included coinductive families, i.e. terminal coalgebras of
indexed functors, in the present paper. It seems clear that we could
represent coinductive families by following our previous
work~\cite{alti:cont-tcs}; There, 
we showed how to encode M-types, i.e. the coinductive
counterpart of W-types, using a limit construction. To dualize the
construction presented here we have to replace the recursive
definition of $\vec{R}^\mu$ by an inductive definition.

A more serious challenge are mutual inductively (or coinductively)
defined families where one type depends on another. A typical example
is the syntax of Type Theory itself which, to simplify, can be encoded
by mutually defining contexts containing terms, types in a given context 
and terms in a given type:
\begin{gather*}
  \mathrm{Con} \in \Set\\
  \mathrm{Ty} \in \mathrm{Con} \to \Set \\
  \mathrm{Tm} \in \Pi \Gamma\in\mathrm{Con}.\Ty\,\Gamma \to \Set
\end{gather*}
This sort of definition can be justified using Dybjer and Setzer's
inductive-recursive definitions~\cite{DybjerSetzer99,DybjerSetzer06}. 
However, induction-recursion doesn't
seem necessary here because there are no negative occurrences of types
as in universe constructions. Can we extend indexed containers to
capture families of this kind? A promising avenue seems to be to
consider the interpretation of containers in the category of families
or more generally telescopes (arrow categories).

\bibliographystyle{IEEEtran}

\bibliography{ic}
  

\end{document}

